{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c66546d-631a-4a0b-9e86-1623419f4d30",
   "metadata": {},
   "source": [
    "## Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82385c2-5a01-4e58-860e-00010e0e6ba7",
   "metadata": {},
   "source": [
    "The Probability Mass Function (PMF) and Probability Density Function (PDF) are two commonly used mathematical functions in probability theory that describe the probability distribution of a random variable.\n",
    "\n",
    "The PMF is a function that maps each possible outcome of a discrete random variable to its probability of occurrence. In other words, it gives the probability that a random variable takes on a specific value. The PMF is defined for discrete random variables only, and its values are non-negative and sum up to 1.\n",
    "\n",
    "For example, consider a six-sided die that is rolled once. The PMF for this random variable can be represented as:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bfceb03a-40d1-42d7-b842-d59a5ee3b393",
   "metadata": {},
   "source": [
    "Outcome\tPMF\n",
    "1\t1/6\n",
    "2\t1/6\n",
    "3\t1/6\n",
    "4\t1/6\n",
    "5\t1/6\n",
    "6\t1/6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ddebaa-3d0f-472c-a344-f5dde42be33e",
   "metadata": {},
   "source": [
    "This PMF tells us that each possible outcome of the die roll has an equal probability of occurring, which is 1/6.\n",
    "\n",
    "On the other hand, the PDF is a function that describes the probability distribution of a continuous random variable. It gives the relative likelihood of a continuous random variable taking on a specific value. Unlike the PMF, the PDF does not give the probability of a specific value, but rather the probability of a value falling within a certain range.\n",
    "\n",
    "For example, consider a random variable X that represents the height of students in a class. The PDF for this random variable could be a normal distribution with a mean of 5 feet and a standard deviation of 0.5 feet. The PDF would be a smooth curve that represents the relative likelihood of a student having a certain height. The area under the curve between two points represents the probability that the student's height falls within that range.\n",
    "\n",
    "Overall, the PMF and PDF are useful mathematical tools for understanding and analyzing probability distributions of random variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1e6995-349c-4f6d-b121-3fac2601a73a",
   "metadata": {},
   "source": [
    "## Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "98ae488d-b413-49b3-8d89-6a097c2310ce",
   "metadata": {},
   "source": [
    "The Cumulative Density Function (CDF) is a mathematical function that describes the probability that a random variable X takes a value less than or equal to a given value x. In other words, it gives the cumulative distribution of the probability of the random variable X.\n",
    "\n",
    "The CDF is defined for both discrete and continuous random variables and is an essential tool for probability theory and statistics. It is also commonly used in data analysis and hypothesis testing.\n",
    "\n",
    "For a discrete random variable, the CDF can be calculated as the sum of the probabilities of all outcomes less than or equal to x. For a continuous random variable, the CDF is obtained by integrating the PDF from negative infinity to x.\n",
    "\n",
    "For example, consider a random variable X that represents the number of heads obtained when flipping a coin three times. The possible outcomes for this random variable are 0, 1, 2, or 3. The PMF for this random variable can be represented as:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a2af8c9a-94e3-4756-89e2-43682349989f",
   "metadata": {},
   "source": [
    "\n",
    "Outcome\tPMF\n",
    "0\t1/8\n",
    "1\t3/8\n",
    "2\t3/8\n",
    "3\t1/8"
   ]
  },
  {
   "cell_type": "raw",
   "id": "62ac82e5-d838-4e61-9e07-9ee801d5a357",
   "metadata": {},
   "source": [
    "The CDF for this random variable can be calculated as follows:\n",
    "\n",
    "x\tCDF\n",
    "0\t1/8\n",
    "1\t4/8\n",
    "2\t7/8\n",
    "3\t8/8\n",
    "This CDF tells us that the probability of getting zero or fewer heads is 1/8, the probability of getting one or fewer heads is 4/8, the probability of getting two or fewer heads is 7/8, and the probability of getting three or fewer heads (i.e., getting all tails or at least one head) is 1.\n",
    "\n",
    "The CDF is used for various purposes in probability theory and statistics, such as calculating percentiles, finding the median or quartiles, and performing hypothesis testing. The CDF also provides a convenient way to compare different probability distributions and to visualize the distribution of a random variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94210ce7-fe53-488c-a33c-eedfc0a740f0",
   "metadata": {},
   "source": [
    "## Q3: What are some examples of situations where the normal distribution might be used as a model? Explain how the parameters of the normal distribution relate to the shape of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb718f66-2fc5-4fa6-895b-a38c94b16bad",
   "metadata": {},
   "source": [
    "The normal distribution, also known as the Gaussian distribution, is a probability distribution that is widely used to model a variety of phenomena in natural and social sciences. Some examples of situations where the normal distribution might be used as a model are:\n",
    "\n",
    "1. Heights and weights of people\n",
    "2. Test scores of a large group of students\n",
    "3. Errors in measurements or observations\n",
    "4. Stock prices and financial returns\n",
    "5. Time taken to complete a task or process\n",
    "6. Physical properties of materials such as strength and elasticity\n",
    "\n",
    "\n",
    "The normal distribution is characterized by two parameters: the mean and the standard deviation. The mean is the center of the distribution and represents the average value of the data. The standard deviation measures the spread or variability of the data around the mean.\n",
    "\n",
    "The shape of the normal distribution is symmetric and bell-shaped, with the highest point located at the mean. The spread of the distribution is determined by the standard deviation: a larger standard deviation results in a wider and flatter distribution, while a smaller standard deviation results in a narrower and taller distribution. The probability of a value falling within a certain range of the distribution can be calculated using the CDF, which is defined in terms of the mean and standard deviation.\n",
    "\n",
    "The normal distribution has several properties that make it a useful model for many real-world phenomena. For example, the Central Limit Theorem states that the sum or average of a large number of independent and identically distributed random variables is approximately normally distributed, regardless of the distribution of the individual variables. This theorem is applicable to many practical situations, such as sampling from a population, and is one of the reasons why the normal distribution is so widely used in statistics and data analysis.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8abce66-7d61-4957-abde-bb142523fb01",
   "metadata": {},
   "source": [
    "## Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal Distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f8d4ee-a4f8-41f1-97f0-ac26d7525722",
   "metadata": {},
   "source": [
    "The normal distribution is an essential concept in statistics and probability theory, and it plays a crucial role in modeling a wide range of natural and social phenomena. Here are some of the key reasons why the normal distribution is important:\n",
    "\n",
    "The normal distribution is widely used as a model for many real-world phenomena, particularly in situations where there is a large number of independent and identically distributed variables that contribute to the outcome of the process. For example, the heights and weights of people, test scores of a large group of students, and errors in measurements or observations are often modeled using the normal distribution.\n",
    "\n",
    "The normal distribution has several important properties that make it a useful model in statistical inference and hypothesis testing. For example, many statistical tests are based on the assumption of normality, which allows researchers to make inferences about the population based on a sample.\n",
    "\n",
    "The normal distribution provides a framework for understanding the behavior of other probability distributions. Many other distributions, such as the t-distribution and the F-distribution, are derived from the normal distribution and are used in statistical analysis.\n",
    "\n",
    "The normal distribution has practical applications in many fields, such as finance, engineering, and medicine. For example, in finance, the normal distribution is used to model stock prices and financial returns, and in engineering, it is used to model the strength and elasticity of materials.\n",
    "\n",
    "Here are some real-life examples of situations where the normal distribution is commonly used as a model:\n",
    "\n",
    "1. Heights and weights of people\n",
    "2. IQ scores and test scores of a large group of students\n",
    "3.  Errors in measurements or observations, such as in manufacturing or scientific experiments\n",
    "4. Monthly returns on investments in the stock market\n",
    "5. Blood pressure measurements in a population\n",
    "6. Reaction times in psychological experiments\n",
    "7. The weight of eggs produced by a particular breed of chicken\n",
    "8. The time taken to complete a task or process, such as customer service calls in a call center\n",
    "9. The amount of rainfall in a region over a given period of time\n",
    "10. The number of defects in a manufacturing process.\n",
    "These are just a few examples, and there are many other situations where the normal distribution can be used as a useful model.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee4b1e0-ac6c-49b1-bc7b-51d2c49663f3",
   "metadata": {},
   "source": [
    "## Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli Distribution and Binomial Distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b362662-ad41-45f4-92db-919e740a7b4c",
   "metadata": {},
   "source": [
    "The Bernoulli distribution is a discrete probability distribution that models the outcomes of a single experiment that has only two possible outcomes, often referred to as \"success\" and \"failure.\" The Bernoulli distribution is named after the Swiss mathematician Jacob Bernoulli, who studied it extensively in the 18th century.\n",
    "\n",
    "The Bernoulli distribution has only one parameter, p, which represents the probability of a success in a single trial. The probability mass function of the Bernoulli distribution is given by:\n",
    "\n",
    "P(X = x) = p^x * (1 - p)^(1-x) for x = 0 or 1\n",
    "\n",
    "where X is a random variable that takes on the value of 1 with probability p and the value of 0 with probability (1-p).\n",
    "\n",
    "An example of a Bernoulli trial is flipping a coin, where success can be defined as the coin landing on heads, and failure can be defined as the coin landing on tails. In this case, p = 0.5 since there is an equal probability of the coin landing on heads or tails.\n",
    "\n",
    "The binomial distribution, on the other hand, models the number of successes in a fixed number of independent Bernoulli trials. The binomial distribution has two parameters: n, which represents the number of trials, and p, which represents the probability of success in each trial. The probability mass function of the binomial distribution is given by:\n",
    "\n",
    "P(X = k) = (n choose k) * p^k * (1-p)^(n-k) for k = 0, 1, 2, ..., n\n",
    "\n",
    "where X is a random variable that takes on the values of 0, 1, 2, ..., or n, and (n choose k) is the binomial coefficient that represents the number of ways to choose k successes from n trials.\n",
    "\n",
    "The main difference between the Bernoulli distribution and the binomial distribution is that the Bernoulli distribution models the outcomes of a single trial, while the binomial distribution models the number of successes in a fixed number of independent Bernoulli trials. The Bernoulli distribution is a special case of the binomial distribution, where n = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a9b297-a4f4-4d03-b931-2ae572d9200e",
   "metadata": {},
   "source": [
    "## Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset is normally distributed, what is the probability that a randomly selected observation will be greater than 60? Use the appropriate formula and show your calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5898ad9c-9487-4998-abe4-a05294ec9936",
   "metadata": {},
   "source": [
    "To calculate the probability that a randomly selected observation from a normally distributed dataset with mean 50 and standard deviation 10 will be greater than 60, we can use the standard normal distribution and the z-score formula.\n",
    "\n",
    "The z-score formula is:\n",
    "\n",
    "z = (x - mu) / sigma\n",
    "\n",
    "where x is the value we are interested in, mu is the population mean, and sigma is the population standard deviation.\n",
    "\n",
    "In this case, x = 60, mu = 50, and sigma = 10. So, the z-score is:\n",
    "\n",
    "z = (60 - 50) / 10 = 1\n",
    "\n",
    "We can use a standard normal distribution table or calculator to find the probability associated with a z-score of 1. The probability of getting a z-score of 1 or greater is approximately 0.1587.\n",
    "\n",
    "Therefore, the probability that a randomly selected observation from a normally distributed dataset with mean 50 and standard deviation 10 will be greater than 60 is approximately 0.1587 or 15.87%.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5078a537-6da2-433e-b163-316f41b46b25",
   "metadata": {},
   "source": [
    "## Q7: Explain uniform Distribution with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0506b523-8bf4-429f-b387-d4dc04d498cd",
   "metadata": {},
   "source": [
    "The uniform distribution is a continuous probability distribution that has a constant probability density function (PDF) between two points, a and b, and zero elsewhere. The uniform distribution is often used to model situations where every outcome in an interval is equally likely to occur.\n",
    "\n",
    "The PDF of a uniform distribution is:\n",
    "\n",
    "f(x) = 1 / (b - a) for a ≤ x ≤ b\n",
    "f(x) = 0 otherwise\n",
    "\n",
    "where a and b are the minimum and maximum values of the interval.\n",
    "\n",
    "For example, let's say that a fair coin is flipped and we are interested in the probability of getting a value between 0 and 1. We can model this situation using a uniform distribution with a = 0 and b = 1. In this case, the PDF of the uniform distribution is:\n",
    "\n",
    "f(x) = 1 / (1 - 0) = 1 for 0 ≤ x ≤ 1\n",
    "f(x) = 0 otherwise\n",
    "\n",
    "This means that the probability of getting a value between 0 and 1 is the same for every possible value, and is equal to 1 / (1 - 0) = 1. The cumulative distribution function (CDF) of the uniform distribution is given by:\n",
    "\n",
    "F(x) = 0 for x < a\n",
    "F(x) = (x - a) / (b - a) for a ≤ x ≤ b\n",
    "F(x) = 1 for x > b\n",
    "\n",
    "The CDF represents the probability of getting a value less than or equal to x. In the case of our coin flip example, the CDF of the uniform distribution is:\n",
    "\n",
    "F(x) = 0 for x < 0\n",
    "F(x) = x for 0 ≤ x ≤ 1\n",
    "F(x) = 1 for x > 1\n",
    "\n",
    "This means that the probability of getting a value less than or equal to 0.5 is 0.5, and the probability of getting a value less than or equal to 0.8 is 0.8. The uniform distribution is useful in situations where all outcomes are equally likely, and can be used to model a wide range of real-world phenomena, such as the distribution of rainfall over a region or the arrival times of customers at a store.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83048a11-47db-421d-8889-c83ba32265be",
   "metadata": {},
   "source": [
    "## Q8: What is the z score? State the importance of the z score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe291b9-da6d-495e-8030-df4dce2a7505",
   "metadata": {},
   "source": [
    "The z-score, also known as the standard score, is a measure of how many standard deviations a data point is from the mean of a distribution. It is calculated by subtracting the mean from the data point and then dividing by the standard deviation. The formula for the z-score is:\n",
    "\n",
    "z = (x - μ) / σ\n",
    "\n",
    "where z is the z-score, x is the data point, μ is the mean of the distribution, and σ is the standard deviation of the distribution.\n",
    "\n",
    "The z-score is important because it allows us to compare data from different distributions that may have different means and standard deviations. By converting data to z-scores, we can standardize it and make meaningful comparisons between different datasets.\n",
    "\n",
    "For example, suppose we have two datasets, one with a mean of 50 and a standard deviation of 10, and another with a mean of 70 and a standard deviation of 5. If we want to compare a data point of 60 from the first dataset to the second dataset, we can convert it to a z-score using the formula above.\n",
    "\n",
    "For the first dataset:\n",
    "z = (60 - 50) / 10 = 1\n",
    "\n",
    "For the second dataset:\n",
    "z = (60 - 70) / 5 = -2\n",
    "\n",
    "This tells us that the value of 60 is 1 standard deviation above the mean in the first dataset, but 2 standard deviations below the mean in the second dataset. Without the z-score, it would be difficult to compare these values directly.\n",
    "\n",
    "The z-score is also used in hypothesis testing, where it helps us to determine the probability of obtaining a particular sample mean or difference in means if the null hypothesis were true. In this context, the z-score is often compared to a critical value from a standard normal distribution to determine whether the null hypothesis should be rejected or not.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91f04a5-22da-4eba-bb8d-b3f133a794fc",
   "metadata": {},
   "source": [
    "## Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0090f170-88df-49e9-893c-f3b68d67be7a",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) is a statistical theory that states that the sampling distribution of the sample mean from a large population will be approximately normally distributed, regardless of the underlying distribution of the population, as long as the sample size is sufficiently large (usually, n > 30).\n",
    "\n",
    "More specifically, the CLT states that as the sample size increases, the distribution of the sample mean will approach a normal distribution with a mean equal to the population mean and a standard deviation equal to the population standard deviation divided by the square root of the sample size.\n",
    "\n",
    "The significance of the Central Limit Theorem is that it provides a powerful tool for statistical inference, as it allows us to make inferences about the population mean using the sample mean, even when the underlying population distribution is not normal. The normal distribution is widely used in statistical inference, and the CLT provides a theoretical justification for this.\n",
    "\n",
    "The CLT has important practical applications in many areas of science and engineering. For example, it is used in quality control to assess whether a process is producing items within a certain specification limit, in finance to model stock price changes, and in psychology to assess the effectiveness of a treatment or intervention. The CLT also forms the basis for many statistical methods, such as hypothesis testing and confidence interval estimation.\n",
    "\n",
    "In summary, the Central Limit Theorem is a fundamental concept in statistics that allows us to make statistical inferences about population parameters based on sample data, even when the underlying population distribution is not normal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dd8cf4-3ec1-46df-9ddd-08e0fbd2ea8c",
   "metadata": {},
   "source": [
    "## Q10: State the assumptions of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3f67fb-743b-44c0-8063-5bbff8889a56",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) is a statistical theory that states that the sampling distribution of the sample mean from a large population will be approximately normally distributed, regardless of the underlying distribution of the population, as long as the sample size is sufficiently large (usually, n > 30). However, the CLT does make some assumptions about the underlying population:\n",
    "\n",
    "1. Independence: The sample observations should be independent of each other. This means that the value of one observation should not influence the value of another observation.\n",
    "\n",
    "2. Random Sampling: The sample should be selected randomly from the population. This means that every member of the population should have an equal chance of being selected for the sample.\n",
    "\n",
    "3. Finite Population: If the population is infinite, the sample size should be less than 10% of the population. If the population is finite, the sample size should be less than 5% of the population.\n",
    "\n",
    "4. Similarity of the Sample Size: The sample size should be large enough so that the distribution of the sample mean is approximately normal, regardless of the shape of the population distribution.\n",
    "\n",
    "5. Finite Mean and Variance: The population should have a finite mean and a finite variance.\n",
    "\n",
    "It is important to note that violating any of these assumptions may result in the CLT not holding, and the sample mean not being approximately normally distributed. Therefore, it is important to carefully consider these assumptions when applying the CLT in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b71961-d4c3-4dc1-a835-fba8f2570f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf6581b-2cf4-40a2-9cea-307fc0fc8350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88365637-e101-454b-b72d-1c3aead16952",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
