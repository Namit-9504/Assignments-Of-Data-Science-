{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "549ae236-6955-47b3-b047-eca254c354e3",
   "metadata": {},
   "source": [
    "## 1. You are working on a machine learning project where you have a dataset containing numerical and categorical features. You have identified that some of the features are highly correlated and there are missing values in some of the columns. You want to build a pipeline that automates the feature engineering process and handles the missing values.\n",
    "Design a pipeline that includes the following steps\"\n",
    "\n",
    "Use an automated feature selection method to identify the important features in the dataset\n",
    "\n",
    "Create a numerical pipeline that includes the following steps\"\n",
    "\n",
    "Impute the missing values in the numerical columns using the mean of the column values\n",
    "\n",
    "Scale the numerical columns using standardisation\n",
    "\n",
    "Create a categorical pipeline that includes the following steps\"\n",
    "\n",
    "Impute the missing values in the categorical columns using the most frequent value of the column\n",
    "\n",
    "One-hot encode the categorical columns\n",
    "\n",
    "Combine the numerical and categorical pipelines using a ColumnTransformer\n",
    "\n",
    "Use a Random Forest Classifier to build the final model\n",
    "\n",
    "Evaluate the accuracy of the model on the test dataset\n",
    "\n",
    "Note! Your solution should include code snipets for each step of the pipeline, and a brief explanation of each step. You should also proide an interpretation of the results and suggest possible improvements for the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30906f04-6d06-4a8a-a888-07acbeb9496d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler , OneHotEncoder ,LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "181b3053-4996-4ce9-b208-c943bf951808",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=sns.load_dataset('tips') ## consider this data set as  a given data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99f017f3-e6c2-43e8-885c-7afd2c5a0cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.59</td>\n",
       "      <td>3.61</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill   tip     sex smoker  day    time  size\n",
       "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
       "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
       "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
       "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
       "4       24.59  3.61  Female     No  Sun  Dinner     4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08fa7fa7-9c41-4db6-a5dc-37e4ab628ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### AUTOMAte feature engineering\n",
    "features=[]\n",
    "\n",
    "cat_cols=['sex','smoker','day']\n",
    "num_cols=['total_bill','tip','size']\n",
    "\n",
    "\n",
    "num_pipeline=Pipeline(\n",
    "    steps=[\n",
    "        ('impute',SimpleImputer(strategy='median')), ## handling missing values\n",
    "        ('scaler',StandardScaler())  ## handling outliers by scaling\n",
    "    ]\n",
    ")\n",
    "\n",
    "cat_pipline = Pipeline(\n",
    "    steps=[\n",
    "        ('impute',SimpleImputer(strategy='most_frequent')),#,# handling missing values\n",
    "        ('encoder',OneHotEncoder())\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num_pipline',num_pipeline,num_cols),\n",
    "    ('cat_pipeline',cat_pipline,cat_cols)\n",
    "])\n",
    "\n",
    "\n",
    "encoder=LabelEncoder()\n",
    "df['time']=encoder.fit_transform(df['time'])\n",
    "\n",
    "\n",
    "X=df.drop(labels=['time'],axis=1)\n",
    "y=df['time']\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.30,random_state=42)\n",
    "\n",
    "X_train=preprocessor.fit_transform(X_train)\n",
    "X_test=preprocessor.transform(X_test)\n",
    "\n",
    "\n",
    "### automate the models \n",
    "\n",
    "models={\n",
    "    'rfc':RandomForestClassifier()\n",
    "}\n",
    "\n",
    "### createing the final function to automate all the above things \n",
    "def evalute_model(X_train,X_test,y_train,y_test,models):\n",
    "    report={}\n",
    "    for i in range(len(models)):\n",
    "        model=list(models.values())[i]\n",
    "        \n",
    "        ## training the model\n",
    "        \n",
    "        model.fit(X_train,y_train)\n",
    "        \n",
    "        \n",
    "        ## predict data\n",
    "        \n",
    "        y_pred=model.predict(X_test)\n",
    "        \n",
    "        model_test_score=accuracy_score(y_test,y_pred)\n",
    "        \n",
    "        report[list(models.keys())[i]]=model_test_score\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7595025-c042-4d80-b2d3-d85398ff6796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rfc': 0.972972972972973}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalute_model(X_train,X_test,y_train,y_test,models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5bc49d-7800-456e-8b70-fae8c5480a51",
   "metadata": {},
   "source": [
    "The provided code snippet is a Python script that automates the feature engineering process, trains machine learning models, and evaluates their performance on a given dataset. Let's break down the code step by step:\n",
    "\n",
    "1. **Feature Engineering Pipelines:**\n",
    "   - Two separate pipelines are defined, one for numerical features (`num_pipeline`) and one for categorical features (`cat_pipeline`).\n",
    "   - The numerical pipeline performs two preprocessing steps: imputation of missing values using the median strategy and scaling of the numerical columns using standardization. Scaling helps handle outliers and brings all numerical features to a similar scale.\n",
    "   - The categorical pipeline handles missing values in categorical columns using the most frequent strategy and then performs one-hot encoding to convert categorical variables into a binary format suitable for machine learning algorithms.\n",
    "   - The `ColumnTransformer` (`preprocessor`) is used to combine the numerical and categorical pipelines, applying each to the corresponding columns in the dataset.\n",
    "\n",
    "2. **Label Encoding:**\n",
    "   - The 'time' column in the DataFrame (`df`) is transformed using `LabelEncoder()` to convert the 'time' labels into numeric format. This is often done to represent categorical labels as numerical values, making them compatible with certain machine learning algorithms.\n",
    "\n",
    "3. **Data Splitting:**\n",
    "   - The DataFrame `df` is split into features `X` and target variable `y`. The 'time' column is considered the target variable, and the rest of the columns are treated as features.\n",
    "   - The data is further split into training and testing sets using `train_test_split`.\n",
    "\n",
    "4. **Automated Model Evaluation:**\n",
    "   - The function `evaluate_model` automates the process of training and evaluating machine learning models on the dataset.\n",
    "   - The function takes the training and testing data along with a dictionary of machine learning models (`models`) as input.\n",
    "   - For each model in the `models` dictionary, it fits the model to the training data and predicts on the testing data.\n",
    "   - The accuracy score is calculated for each model by comparing the predicted labels with the true labels (`y_test`), and the scores are stored in the `report` dictionary.\n",
    "   - The function returns the `report` dictionary containing model names as keys and their corresponding accuracy scores as values.\n",
    "\n",
    "5. **Model Automation and Evaluation:**\n",
    "   - In the provided code snippet, a single model, `RandomForestClassifier()`, is included in the `models` dictionary.\n",
    "   - The `evalute_model` function is called with the training and testing data along with the `models` dictionary.\n",
    "   - The function returns the accuracy score for the `RandomForestClassifier` model on the test data.\n",
    "\n",
    "The code aims to automate the feature engineering and model evaluation processes, making it easier to try multiple models and assess their performance on the dataset. It demonstrates how to use pipelines for feature engineering, label encoding for categorical variables, and a function to automate the model evaluation process.\n",
    "\n",
    "However, it's worth noting that in practice, the code can be further enhanced by trying different models, tuning hyperparameters, and performing cross-validation to get more reliable performance estimates. Additionally, model selection should be based on the problem's requirements and characteristics of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41a4578-0df1-434d-b9a1-39070641461e",
   "metadata": {},
   "source": [
    "## Q2. Build a pipeline that includes a random forest classifier and a logistic regression classifier, and then use a voting classifier to combine their predictions. Train the pipeline on the iris dataset and evaluate its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f360ebbf-6d68-4e03-a1e8-c0d4a498b1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler , OneHotEncoder ,LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier,VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0902b844-f375-48c0-878b-824dd23cadaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=sns.load_dataset('iris')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eef94979-0751-4e74-8856-5e8a84a3aab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### AUTOMAte feature engineering\n",
    "features=[]\n",
    "\n",
    "\n",
    "num_cols=['sepal_length','sepal_width','petal_length','petal_width']\n",
    "\n",
    "\n",
    "num_pipeline=Pipeline(\n",
    "    steps=[\n",
    "        ('impute',SimpleImputer(strategy='median')), ## handling missing values\n",
    "        ('scaler',StandardScaler())  ## handling outliers by scaling\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num_pipline',num_pipeline,num_cols)\n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "encoder=LabelEncoder()\n",
    "df['species']=encoder.fit_transform(df['species'])\n",
    "\n",
    "\n",
    "X=df.drop(labels=['species'],axis=1)\n",
    "y=df['species']\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.30,random_state=42)\n",
    "\n",
    "X_train=preprocessor.fit_transform(X_train)\n",
    "X_test=preprocessor.transform(X_test)\n",
    "\n",
    "\n",
    "### automate the models \n",
    "\n",
    "models={\n",
    "    'rfc':RandomForestClassifier(),\n",
    "    'LR':LogisticRegression()\n",
    "}\n",
    "\n",
    "### createing the final function to automate all the above things \n",
    "def evalute_model(X_train,X_test,y_train,y_test,models):\n",
    "    report={}\n",
    "    for i in range(len(models)):\n",
    "        model=list(models.values())[i]\n",
    "        \n",
    "        ## training the model\n",
    "        \n",
    "        \n",
    "        ## predict data\n",
    "       \n",
    "        voting_classifier = VotingClassifier(\n",
    "            estimators=[('rf', RandomForestClassifier()), ('lr', LogisticRegression())],\n",
    "            voting='hard'  # Use majority voting\n",
    "        )\n",
    "        # : Fit the Voting Classifier to the training data\n",
    "        voting_classifier.fit(X_train, y_train)\n",
    "        \n",
    "        #: Make predictions on the test data\n",
    "        \n",
    "        y_pred = voting_classifier.predict(X_test)\n",
    "        \n",
    "        model_test_score=accuracy_score(y_test,y_pred)\n",
    "        \n",
    "        report['voting_classiferi_score']=model_test_score\n",
    "    return report\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7fca2cf-ba01-4500-bbd5-d85233f6ef1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'voting_classiferi_score': 1.0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalute_model(X_train,X_test,y_train,y_test,models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577505cc-0a12-4a31-82ef-ee0573bc23f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8a6246-7f5a-4e74-a79b-613d0dad6482",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231b2298-08b8-437f-a70f-bdc56a7cf760",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c02363-7a11-4ddc-9932-b5e518ec0656",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
